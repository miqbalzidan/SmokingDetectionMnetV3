{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import package and module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "B5XzxVF5Xve3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "from itertools import zip_longest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26gzMN-EdU8I",
        "outputId": "0dc480d5-9bbd-430e-d92f-5abdbeb7be56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon May  9 16:03:55 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.89       Driver Version: 460.89       CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  GeForce GTX 166... WDDM  | 00000000:29:00.0  On |                  N/A |\n",
            "|  0%   47C    P8    19W / 125W |    629MiB /  6144MiB |     17%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      1252    C+G   C:\\Windows\\System32\\dwm.exe     N/A      |\n",
            "|    0   N/A  N/A      3352    C+G   ...kyb3d8bbwe\\Calculator.exe    N/A      |\n",
            "|    0   N/A  N/A      5924    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
            "|    0   N/A  N/A      6200    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
            "|    0   N/A  N/A      6724    C+G   ...ekyb3d8bbwe\\HxOutlook.exe    N/A      |\n",
            "|    0   N/A  N/A      6868    C+G   ...ll\\1.0.0.443\\LineCall.exe    N/A      |\n",
            "|    0   N/A  N/A      8204    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A      8652    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
            "|    0   N/A  N/A      8708    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
            "|    0   N/A  N/A      9880    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
            "|    0   N/A  N/A     10628    C+G   ...wekyb3d8bbwe\\Music.UI.exe    N/A      |\n",
            "|    0   N/A  N/A     10640    C+G   ...wekyb3d8bbwe\\Video.UI.exe    N/A      |\n",
            "|    0   N/A  N/A     10900    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
            "|    0   N/A  N/A     10988    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A     12172    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
            "|    0   N/A  N/A     13140    C+G   ...LINE\\bin\\current\\LINE.exe    N/A      |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "tf.config.list_physical_devices(\"GPU\")\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGY-cAkI0NUu"
      },
      "source": [
        "# Load path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "H_GbHtqVoouP"
      },
      "outputs": [],
      "source": [
        "train_dir = './cigarette-smoker-detection-kaggle/train'\n",
        "test_dir = './cigarette-smoker-detection-kaggle/test'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxSgOQIHokq1"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPL9hbdGpdOh"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fxfei6v8punH",
        "outputId": "77bfc042-7cc4-4fe2-e7d3-c42e116ab504"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3185 files belonging to 2 classes.\n",
            "Using 2548 files for training.\n",
            "Found 3185 files belonging to 2 classes.\n",
            "Using 637 files for validation.\n"
          ]
        }
      ],
      "source": [
        "img_size = 224\n",
        "batch_size = 32\n",
        "seed = 72\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=seed,\n",
        "    label_mode=\"binary\",\n",
        "    image_size=(img_size, img_size),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=seed,\n",
        "    label_mode=\"binary\",\n",
        "    image_size=(img_size,img_size),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    seed=seed,\n",
        "    label_mode=\"binary\",\n",
        "    image_size=(img_size, img_size),\n",
        "    batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKBPFyV_xdcX",
        "outputId": "47a79b29-4ec4-455d-ade0-c6cc16f3504d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['not_smoking', 'smoking']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds.class_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ietuHeAUNDuy"
      },
      "source": [
        "## Rescale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3Lm_Cxe6NNXt"
      },
      "outputs": [],
      "source": [
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "print(\"\\nRescale Successful\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDBa_FR0Osk3"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sseo35IhOuMR",
        "outputId": "3d8eab4e-4c2d-4b73-a29b-a3356b0f21db"
      },
      "outputs": [],
      "source": [
        "base_model = tf.keras.applications.MobileNetV3Large(\n",
        "    input_shape=(img_size, img_size, 3),\n",
        "    weights=\"imagenet\",\n",
        "    include_preprocessing=False,\n",
        "    include_top=False,\n",
        "    pooling=\"avg\"\n",
        ")\n",
        "\n",
        "base_model.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0g2OSXt0Smpr"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             base_model,\n",
        "                             tf.keras.layers.Dropout(0.2),\n",
        "                             tf.keras.layers.Dense(units=1, activation = \"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bnyLtIBmVzmg"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\", \n",
        "                       tf.keras.metrics.Precision(),\n",
        "                       tf.keras.metrics.Recall()\n",
        "                       #,tfa.metrics.F1Score(num_classes= 2 )\n",
        "                       ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0NyGqt2WK9_"
      },
      "source": [
        "Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "id": "qPGLDcZ5Vj0g",
        "outputId": "f5416df3-ce53-45ec-fae3-1e448618ad9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " MobilenetV3large (Functiona  (None, 960)              2996352   \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 960)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 961       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,997,313\n",
            "Trainable params: 961\n",
            "Non-trainable params: 2,996,352\n",
            "_________________________________________________________________\n",
            "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
          ]
        }
      ],
      "source": [
        "model.summary()\n",
        "\n",
        "tf.keras.utils.plot_model(\n",
        "    model,\n",
        "    show_shapes=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Start train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n"
          ]
        },
        {
          "ename": "Error",
          "evalue": "Canceled future for execute_request message before replies were done",
          "output_type": "error",
          "traceback": [
            "Error: Canceled future for execute_request message before replies were done",
            "at t.KernelShellFutureHandler.dispose (c:\\Users\\Aisen\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:1204175)",
            "at c:\\Users\\Aisen\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:1223227",
            "at Map.forEach (<anonymous>)",
            "at v._clearKernelState (c:\\Users\\Aisen\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:1223212)",
            "at v.dispose (c:\\Users\\Aisen\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:1216694)",
            "at c:\\Users\\Aisen\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:533674",
            "at t.swallowExceptions (c:\\Users\\Aisen\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:913059)",
            "at dispose (c:\\Users\\Aisen\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:533652)",
            "at t.RawSession.dispose (c:\\Users\\Aisen\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:537330)",
            "at runMicrotasks (<anonymous>)",
            "at processTicksAndRejections (node:internal/process/task_queues:96:5)"
          ]
        }
      ],
      "source": [
        "history_1 = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=3,\n",
        "    steps_per_epoch=len(train_ds),\n",
        "    validation_steps=len(val_ds)\n",
        ")\n",
        "\n",
        "print(\"\\n==========================\")\n",
        "print(\"======= Train done =======\")\n",
        "print(\"==========================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Result #1 train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "acc = history_1.history['accuracy']\n",
        "prec = history_1.history['precision']\n",
        "recall = history_1.history['recall']\n",
        "loss = history_1.history['loss']\n",
        "\n",
        "val_acc = history_1.history['val_accuracy']\n",
        "val_prec = history_1.history['val_precision']\n",
        "val_recall = history_1.history['val_recall']\n",
        "val_loss = history_1.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3large_input with unsupported characters which will be renamed to mobilenetv3large_input in the SavedModel.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./Developed-model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./Developed-model\\assets\n"
          ]
        }
      ],
      "source": [
        "save_path = './Developed-model/test'\n",
        "model.save(save_path)\n",
        "print(\"\\nModel has been saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 1s 397ms/step - loss: 0.8472 - accuracy: 0.6556 - precision: 0.5921 - recall: 1.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.8472484946250916, 0.6555555462837219, 0.5921052694320679, 1.0]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"\\nEvaluating the model with test set\")\n",
        "model.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Export Fine tune 1 metrics result to csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = [acc, prec, recall, loss, val_acc, val_prec, val_recall, val_loss]\n",
        "export_data = zip_longest(*data, fillvalue = '')\n",
        "\n",
        "with open('train_test_result.csv', 'w', encoding=\"ISO-8859-1\", newline='') as file:\n",
        "      write = csv.writer(file)\n",
        "      write.writerow((\"acc\", \"prec\", \"recall\", \"loss\", \"val_acc\", \"val_prec\", \"val_recall\", \"val_loss\"))\n",
        "      write.writerows(export_data)\n",
        "\n",
        "print(\"\\nTrain result has been saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "plt.figure(figsize=(20, 16))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(prec, label='Training Precision')\n",
        "plt.plot(val_prec, label='Validation Precision')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Precision')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Precision')\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(recall, label='Training Recall')\n",
        "plt.plot(val_recall, label='Validation Recall')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Recall')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Recall')\n",
        "\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "eGY-cAkI0NUu",
        "bxSgOQIHokq1",
        "ietuHeAUNDuy"
      ],
      "name": "smoker-detectin-Mnetv3.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "03869a44261c6371b34f5426981a954ad5f80c333b73adca2fd233cc85bef991"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('myenv': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
